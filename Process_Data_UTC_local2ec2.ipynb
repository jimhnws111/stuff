{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import collections\n",
    "import datetime as datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timezone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/TEST996.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# reads in the JSON file as a Python dictionary\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m fr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ec2-user/TEST996.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m dataAPI \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/TEST996.json'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# reads in the JSON file as a Python dictionary\n",
    "#\n",
    "\n",
    "fr = open('/home/ec2-user/TEST996.json')\n",
    "dataAPI = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataAPI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSome basic error checking to see if the Max/Min data is available\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mfor each station, and adds a dummy value if it is not there\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataAPI\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATION\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMINMAX\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m \u001b[38;5;66;03m#print('It is here', x, data)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataAPI' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Some basic error checking to see if the Max/Min data is available\n",
    "for each station, and adds a dummy value if it is not there\n",
    "'''\n",
    "\n",
    "x = 0\n",
    "for data in dataAPI['STATION']:\n",
    "    if 'MINMAX' in data:\n",
    "        pass #print('It is here', x, data)\n",
    "    else:\n",
    "        print('it is NOT here', x, data)\n",
    "        data['MINMAX'] = 'None','None','None','None','None'\n",
    "        #print(data)\n",
    "              \n",
    "    x = x + 1 \n",
    "\n",
    "#\n",
    "# Set up filename\n",
    "#\n",
    "\n",
    "dt = (datetime.now(timezone.utc))\n",
    "dt1 = ((dt.strftime(\"%m\")) + \"/\" + (dt.strftime(\"%d\") + \"/\" ) + (dt.strftime(\"%Y\")))\n",
    "dh = (dt.strftime(\"%H%M\"))\n",
    "print()\n",
    "print(f\"There are {x} observations at {dh} UTC on {dt1}\") \n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x = datetime.datetime.now()\n",
    "#print(x)\n",
    "path_to_file = ('/home/ec2-user/')\n",
    "name_of_file = ('Updated_API_')\n",
    "type_of_file = ('.txt')\n",
    "file_time =(((dt.strftime(\"%Y\")) + (dt.strftime(\"%m\")) + (dt.strftime(\"%d\")) + (dt.strftime(\"%H\")) + (dt.strftime(\"%M\"))))\n",
    "file_name = ((path_to_file) + (name_of_file) + (file_time) + (type_of_file))\n",
    "print(file_name)\n",
    "\n",
    "#\n",
    "# Write the text file\n",
    "#\n",
    "\n",
    "with open(file_name, 'w') as outfile:\n",
    "    for data in dataAPI['STATION']:\n",
    "        names = data['NAME'];names1 = names.rstrip();n = names.replace(',','')\n",
    "        stid = data['STID'];stid1 = stid.rstrip()\n",
    "        lat = data['LATITUDE'];lat1 = lat.rstrip()\n",
    "        lon = data['LONGITUDE']; lon1 = lon.strip()\n",
    "        minimaxi = data['MINMAX'];minmax1 = str(minimaxi);minmax2 = minmax1.replace('{','').replace('}','').replace('[','').replace(']','')\n",
    "        minmax3 = minmax2.replace(\"'air_temp_value_1': \",'').replace(\"'dates': \",'')\n",
    "        minmax4 = minmax3.replace(\" 'datetime_min_utc':\",'').replace(\" 'value_min_utc':\",'').replace(\" 'dates':\",'' )\n",
    "        minmax5 = minmax4.replace(\" 'value_max_utc':\",'').replace(\" 'datetime_max_utc':\",'').replace(\" 'datetime_timezone': 'utc',\",'' )\n",
    "        # split minmax5 for a more precise definition\n",
    "        inter = minmax5.split(',')\n",
    "        date_utc = inter[0]\n",
    "        date_max_utc = inter[1]\n",
    "        min_utc = inter[2]\n",
    "        max_utc = inter[3]\n",
    "        date_min_utc = inter[4]\n",
    "        id = data['ID']; id1 = id.rstrip()\n",
    "        obs = data['OBSERVATIONS']\n",
    "        state = data['STATE'];state1 = state.rstrip()\n",
    "        Ev = data['ELEVATION']\n",
    "        if Ev == None: \n",
    "            Ev = \"0\"\n",
    "        tz = data['TIMEZONE'];tz1 =tz.rstrip() \n",
    "        #print(stid1 + \",\", n + \",\", state1 + \",\", lat1 + \",\",lon1 + \",\", Ev + \",\", tz1 + \",\", minmax5, file = outfile)      \n",
    "        print(stid1 + \",\", n + \",\", state1 + \",\", lat1 + \",\",lon1 + \",\", Ev + \",\", tz1 + \",\", date_utc + \",\", min_utc + \",\", date_min_utc + \",\", max_utc + \",\", date_max_utc, file = outfile)    \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Remove liens with missing data\n",
    "#\n",
    "\n",
    "lines = []\n",
    "# read file\n",
    "with open(file_name, 'r') as f:\n",
    "    # read an store all lines into list\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Write file\n",
    "with open(file_name, 'w') as f:\n",
    "    # iterate each line\n",
    "    for line in lines:\n",
    "          \n",
    "        # condition for data to be deleted\n",
    "        if 'None' not in line:\n",
    "        #if line.strip(\"\\n\") != 'None': \n",
    "            f.write(line)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KGIF', 'KDWX', 'TT087', 'CADL1', 'QPSA3', 'KNQI', 'FRCW1', 'WINM6', 'BOLG1', 'FCRM8', 'CPMG1', 'K1CM', 'KMJD', 'TOGC1']\n",
      "There are 14 members of the blacklist\n",
      "read in the file /Users/jameshayes/Updated_API_202210170046.txt\n",
      "writing the file /Users/jameshayes/Updated_API_202210170046.txt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read in the blacklist and remove those lines\n",
    "#\n",
    "\n",
    "values = []\n",
    "lines = []\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Set the path and file name of the blacklist file\n",
    "\n",
    "path_to_file = ('/home/ec2-user/')\n",
    "name_of_file = ('blacklist.txt')\n",
    "\n",
    "new_fileName = f'{path_to_file}{name_of_file}'\n",
    "\n",
    "# read blacklist file\n",
    "\n",
    "try:\n",
    "\n",
    "    with open(new_fileName, 'r') as f:\n",
    "        values = f.readlines()\n",
    "        for i,n in enumerate(values):\n",
    "            values[i] = n.strip(\"\\n\")          \n",
    "        \n",
    "except os.error as err:\n",
    "       print(f\"Unable to open {new_fileName}: {err}\", file=sys.stderr)      \n",
    "                                     \n",
    "dummy_name = 'test1009.txt'\n",
    "dummy_file = f'{path_to_file}{dummy_name}' \n",
    "\n",
    "#number of values\n",
    "a = (len(values))\n",
    "print(values)\n",
    "\n",
    "#\n",
    "# Set the values for checking in the loop\n",
    "#\n",
    "\n",
    "print(f'There are {a} members of the blacklist')\n",
    "        \n",
    "with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(f'read in the file {file_name}')\n",
    "                  \n",
    "with open(file_name, 'w') as fd:\n",
    "         print(f'writing the file {file_name}')\n",
    "         for line in lines:\n",
    "                \n",
    "                result = any(map(line.startswith, values))\n",
    "                if result == False:\n",
    "                    fd.writelines(line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 01z\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Set up panda DataFrames parameters\n",
    "#\n",
    "\n",
    "#\n",
    "# Determine the time\n",
    "#\n",
    "\n",
    "import datetime as datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timezone\n",
    "\n",
    "dt = (datetime.now(timezone.utc))\n",
    "dt1 = ((dt.strftime(\"%m\")) + \"/\" + (dt.strftime(\"%d\") + \"/\" ) + (dt.strftime(\"%Y\")))\n",
    "dh = (dt.strftime(\"%H\"))\n",
    "\n",
    "compTime = dh\n",
    "compTime = int(dh)\n",
    "\n",
    "\n",
    "if compTime >= 0 and compTime < 1:\n",
    "    timeUTC = \"01z\"\n",
    "elif compTime >= 1 and compTime < 6:\n",
    "    timeUTC = \"06z\"    \n",
    "elif compTime >= 6 and compTime < 12:\n",
    "    timeUTC = \"12z\"\n",
    "elif compTime >= 12 and compTime < 13:\n",
    "    timeUTC = \"13z\"\n",
    "elif compTime >= 13 and compTime < 18:\n",
    "    timeUTC = \"18z\"\n",
    "elif compTime >= 18 and compTime < 24:\n",
    "    timeUTC = \"00z\"\n",
    "else:\n",
    "    timeUTC = \"00z\"\n",
    "\n",
    "print(compTime,timeUTC)\n",
    "        \n",
    "df = pd.read_csv(file_name, names = ['STID', 'Location', 'State','Lat', 'Lon', 'Elev','TZ','Date','LOW','Time_Min_UTC','HIGH', 'Time_Max_UTC'] )\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "#\n",
    "# Set the path \n",
    "#\n",
    "\n",
    "new_Path = ('/home/ec2-user/')\n",
    "\n",
    "#\n",
    "# Write the MAX html file first\n",
    "#\n",
    "\n",
    "ccc = (df.sort_values(by=\"HIGH\", ascending=False))\n",
    "cccc = ccc.round({\"HIGH\":0})\n",
    "cccc.head(50).to_html(new_Path + 'Max' + '.html', index = False)\n",
    "\n",
    "#\n",
    "# Now write the MIN html file\n",
    "#\n",
    "\n",
    "ddd = (df.sort_values(by='LOW', ascending=True))\n",
    "dddd = ddd.round({\"LOW\":0})\n",
    "dddd.head(50).to_html(new_Path + 'Min' + '.html', index = False)\n",
    "\n",
    "#\n",
    "# Create a csv file for plotting\n",
    "#\n",
    "\n",
    "df2 = pd.DataFrame().assign(STID=df['STID'], HIGH=df['HIGH'])\n",
    "df3 = pd.DataFrame().assign(STID=df['STID'], LOW=df['LOW'])\n",
    "\n",
    "#\n",
    "# Write the MAX csv file first\n",
    "#\n",
    "\n",
    "eee = (df2.sort_values(by=\"HIGH\", ascending=False))\n",
    "eeee = eee.round({\"HIGH\":0})\n",
    "eeee = eee.round(0)\n",
    "eeee.head(50).to_csv(new_Path + 'Max' + '_' + timeUTC + '.csv', index = False)\n",
    "\n",
    "#\n",
    "# Now write the MIN csv file\n",
    "#\n",
    "\n",
    "fff = (df3.sort_values(by='LOW', ascending=True))\n",
    "ffff = fff.round({\"LOW\":0})\n",
    "ffff = fff.round(0)\n",
    "ffff.head(50).to_csv(new_Path + 'Min' + '_' + timeUTC + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Investigate the feasibility of comparing highs - 00z vs 01z\n",
    "#\n",
    "\n",
    "#df5 = pd.read_csv(f'{new_Path}Max_01z.csv')\n",
    "#df6 = pd.read_csv(f'{new_Path}Max_00z.csv')\n",
    "\n",
    "#newdf = df5.merge(df6, on=['STID'], how='left')\n",
    "#bool_series = pd.isnull(newdf[\"HIGH_y\"])\n",
    "#df7 = newdf[bool_series]\n",
    "\n",
    "#dFinal = df7.drop(['HIGH_x', 'HIGH_y'], axis=1)\n",
    "#dFinal = dFinal.iloc[1: , :]\n",
    "#dFinal.to_csv(f'{new_Path}01z_highSort.csv',index = False)\n",
    "    \n",
    "#with open(f'{new_Path}01z_highSort.csv', 'r') as f:\n",
    "#        sta = f.readlines()\n",
    "#        for i,n in enumerate(sta):\n",
    "#            sta[i] = n.strip(\"\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Investigate the feasibility of comparing lows - 12z vs 13z\n",
    "#\n",
    "\n",
    "df5 = pd.read_csv(f'{new_Path}Min_12z.csv')\n",
    "df6 = pd.read_csv(f'{new_Path}Min_13z.csv')\n",
    "\n",
    "newdf = df5.merge(df6, on=['STID'], how='left')\n",
    "bool_series = pd.isnull(newdf[\"LOW_y\"])\n",
    "df7 = newdf[bool_series]\n",
    "\n",
    "dFinal = df7.drop(['LOW_x', 'LOW_y'], axis=1)\n",
    "#dFinal = dFinal.iloc[1: , :]\n",
    "dFinal.to_csv(f'{new_Path}13z_lowSort.csv',index = False)\n",
    "    \n",
    "with open(f'{new_Path}13z_lowSort.csv', 'r') as f:\n",
    "        sta = f.readlines()\n",
    "        for i,n in enumerate(sta):\n",
    "            sta[i] = n.strip(\"\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport datetime as datetime\\nfrom datetime import datetime  \\nfrom datetime import timezone\\n\\ndt = (datetime.now(timezone.utc))\\ndt1 = ((dt.strftime(\"%m\")) + \"/\" + (dt.strftime(\"%d\") + \"/\" ) + (dt.strftime(\"%Y\")))\\ndh = (dt.strftime(\"%H\"))\\n\\nyy = (dt.strftime(\"%Y\"))\\nmm = (dt.strftime(\"%m\"))\\ndd = (dt.strftime(\"%d\"))\\n\\npref = \"Updated_API_\"\\nstatTime = \"1156\"\\nsuff = \".txt\"\\n\\nnew_Path = (\\'/Users/jameshayes/\\')\\nNew_Filename = (f\\'{new_Path}{pref}{yy}{mm}{dd}{statTime}{suff}\\')\\ntest_File = (f\\'{new_Path}{pref}{yy}{mm}11{statTime}{suff}\\')\\nadd_on_file = (f\\'{new_Path}add_on.txt\\')\\nprint(sta)\\n\\nwith open(test_File, \\'r\\') as f:\\n        lines = f.readlines()\\n        print(f\\'Read in the file {test_File}\\')\\n                  \\nwith open(add_on_file, \\'w\\') as fd:\\n         print(f\\'Writing the file {add_on_file}\\')\\n         for line in lines:\\n                                \\n                result = any(map(line.startswith, sta))\\n                if result == True:\\n                    fd.writelines(line) \\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import datetime as datetime\n",
    "from datetime import datetime  \n",
    "from datetime import timezone\n",
    "\n",
    "dt = (datetime.now(timezone.utc))\n",
    "dt1 = ((dt.strftime(\"%m\")) + \"/\" + (dt.strftime(\"%d\") + \"/\" ) + (dt.strftime(\"%Y\")))\n",
    "dh = (dt.strftime(\"%H\"))\n",
    "\n",
    "yy = (dt.strftime(\"%Y\"))\n",
    "mm = (dt.strftime(\"%m\"))\n",
    "dd = (dt.strftime(\"%d\"))\n",
    "\n",
    "pref = \"Updated_API_\"\n",
    "statTime = \"1156\"\n",
    "suff = \".txt\"\n",
    "\n",
    "new_Path = ('/Users/jameshayes/')\n",
    "New_Filename = (f'{new_Path}{pref}{yy}{mm}{dd}{statTime}{suff}')\n",
    "test_File = (f'{new_Path}{pref}{yy}{mm}11{statTime}{suff}')\n",
    "add_on_file = (f'{new_Path}add_on.txt')\n",
    "print(sta)\n",
    "\n",
    "with open(test_File, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        print(f'Read in the file {test_File}')\n",
    "                  \n",
    "with open(add_on_file, 'w') as fd:\n",
    "         print(f'Writing the file {add_on_file}')\n",
    "         for line in lines:\n",
    "                                \n",
    "                result = any(map(line.startswith, sta))\n",
    "                if result == True:\n",
    "                    fd.writelines(line) \n",
    "'''                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Compare low temperature files for changes\n",
    "\n",
    "file1=(f'{new_Path}Updated_API_202210141156.txt')\n",
    "file2=(f'{new_Path}Updated_API_202210141216.txt')    \n",
    "df8=pd.read_csv(file1, names = ['STID', 'Location', 'State','Lat', 'Lon', 'Elev','TZ','Date','LOW','Time_Min_UTC','HIGH', 'Time_Max_UTC'] )\n",
    "df8.columns =['STID', 'Location', 'State','Lat', 'Lon', 'Elev','TZ','Date','LOW','Time_Min_UTC','HIGH', 'Time_Max_UTC']\n",
    "df9=pd.read_csv(file2, names = ['STID', 'Location', 'State','Lat', 'Lon', 'Elev','TZ','Date','LOW','Time_Min_UTC','HIGH', 'Time_Max_UTC'] )\n",
    "df9.columns =['STID', 'Location', 'State','Lat', 'Lon', 'Elev','TZ','Date','LOW','Time_Min_UTC','HIGH', 'Time_Max_UTC']\n",
    "\n",
    "k10=(df8['STID'],df8['LOW'])\n",
    "df10 = pd.DataFrame(k10)\n",
    "k11=(df9['STID'],df9['LOW'])\n",
    "df11 = pd.DataFrame(k11)\n",
    "\n",
    "\n",
    "#on=['STID'], how='left')\n",
    "#frames = [df10, df11]\n",
    "#result = pd.concat(frames, axis=1)\n",
    "#display(result)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

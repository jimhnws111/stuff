{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import calcTimeStamp\n",
    "from datetime import timezone\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Calculate the time and date for calculations so far\n",
    "\n",
    "xy = calcTimeStamp.calcTimeStamp()\n",
    "start, end = (xy[0], xy[1])\n",
    "start = str(start)\n",
    "end = str(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: \"api-key\" has value \"vy8jbrjsxlbwgojepq3vfyfqfywyhvbd\"\n",
      "Parameter name: \"api-secret\" has value \"sdqfm6wdfy9w0pqp2vdka38o6b4vcsvc\"\n",
      "Parameter name: \"end-timestamp\" has value \"1678578630\"\n",
      "Parameter name: \"start-timestamp\" has value \"1678510800\"\n",
      "Parameter name: \"station-id\" has value \"81211\"\n",
      "Parameter name: \"t\" has value \"1678579318\"\n",
      "Data string to hash is: \"api-keyvy8jbrjsxlbwgojepq3vfyfqfywyhvbdend-timestamp1678578630start-timestamp1678510800station-id81211t1678579318\"\n",
      "\n",
      "\n",
      "API Signature is: \"3a61c4fa1e8e8e57b1e9564db85c4a0eaa257fde982c202246ac6be6381127c1\"\n",
      "\n",
      "\n",
      "https://api.weatherlink.com/v2/historic/81211?api-key=vy8jbrjsxlbwgojepq3vfyfqfywyhvbd&t=1678579318&start-timestamp=1678510800&end-timestamp=1678578630&api-signature=3a61c4fa1e8e8e57b1e9564db85c4a0eaa257fde982c202246ac6be6381127c1\n",
      "<Response [200]>\n",
      "/home/ec2-user/ davis.json data_out.csv /var/www/html/000/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/davis.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/83tjf6dx2d591wslk5wm2wdh0000gn/T/ipykernel_57611/2185041697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURLfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{home_dir}{json_fileName}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m      \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/davis.json'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import hmac\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import soFarVars\n",
    "\n",
    "parameters = {\n",
    "  \"api-key\": \"vy8jbrjsxlbwgojepq3vfyfqfywyhvbd\", \n",
    "  \"api-secret\": \"sdqfm6wdfy9w0pqp2vdka38o6b4vcsvc\",\n",
    "  \"station-id\": 81211, \n",
    "  \"end-timestamp\": end,\n",
    "  \"start-timestamp\": start,\n",
    "  \"t\": int(time.time())\n",
    "}\n",
    "\n",
    "parameters = collections.OrderedDict(sorted(parameters.items()))\n",
    "\n",
    "for key in parameters:\n",
    "    print(\"Parameter name: \\\"{}\\\" has value \\\"{}\\\"\".format(key, parameters[key]))\n",
    "\n",
    "apiSecret = parameters[\"api-secret\"];\n",
    "parameters.pop(\"api-secret\", None);\n",
    "\n",
    "data = \"\"\n",
    "for key in parameters:\n",
    "    data = data + key + str(parameters[key])\n",
    "\n",
    "print(\"Data string to hash is: \\\"{}\\\"\".format(data))\n",
    "print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "Calculate the HMAC SHA-256 hash that will be used as the API Signature.\n",
    "\"\"\"\n",
    "apiSignature = hmac.new(\n",
    "  apiSecret.encode('utf-8'),\n",
    "  data.encode('utf-8'),\n",
    "  hashlib.sha256\n",
    ").hexdigest()\n",
    "\n",
    "\"\"\"\n",
    "Let's see what the final API Signature looks like.\n",
    "\"\"\"\n",
    "print(\"API Signature is: \\\"{}\\\"\".format(apiSignature))\n",
    "print('\\n')\n",
    "\n",
    "# Building the URL to get the station\n",
    "\n",
    "first_part = ('https://api.weatherlink.com/v2/historic/81211?')\n",
    "api_key = ('api-key=vy8jbrjsxlbwgojepq3vfyfqfywyhvbd')\n",
    "add_apisig = ('&api-signature=')\n",
    "add_t = ('&t='+ str(int(time.time())))\n",
    "start1 = \"&start-timestamp=\" + start\n",
    "end1 = \"&end-timestamp=\" + end\n",
    "\n",
    "#\n",
    "URLfinal = (first_part + api_key + add_t + start1 + end1 + add_apisig + apiSignature)\n",
    "print(URLfinal)\n",
    "\n",
    "r =  requests.get(URLfinal)\n",
    "r.encoding = 'utf-8'\n",
    "print(r)\n",
    "\n",
    "#\n",
    "# read in some needed variables \n",
    "#\n",
    "\n",
    "l7 = soFarVars.soFarVars()\n",
    "home_dir, json_fileName, data_out,html_dir = l7[0], l7[1],l7[2],l7[3]\n",
    "\n",
    "r =  requests.get(URLfinal)\n",
    "data_file = f'{home_dir}{json_fileName}' \n",
    "with open(data_file, \"w\") as fd:   \n",
    "     json.dump(r.json(), fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import hmac\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "with open(data_file) as fr:\n",
    "    davisAPI = json.load(fr)\n",
    "    \n",
    "  \n",
    "a = davisAPI['sensors']    \n",
    "b = a[1]\n",
    "c = (b['data'])\n",
    "cLen = len(c)\n",
    "print(cLen)\n",
    "\n",
    "with open(f'{home_dir}{data_out}', 'w') as outfile: \n",
    "    i = 0\n",
    "    while i < cLen:\n",
    "        d = c[i]\n",
    "        hi_temp = (d['temp_hi'])\n",
    "        lo_temp = (d['temp_lo'])\n",
    "        rainfall = (d['rainfall_in'])\n",
    "        print(f'{hi_temp},{lo_temp},{rainfall}', file = outfile)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/www/html/000/HiLoRain.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/data_out.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/83tjf6dx2d591wslk5wm2wdh0000gn/T/ipykernel_57611/3602316629.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{html_dir}HiLoRain.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temp_hi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'temp_lo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rainfall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1440\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/data_out.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#\n",
    "# Read in the CSV file for processing in pandas\n",
    "#\n",
    "\n",
    "full_file = f'{home_dir}{data_out}'\n",
    "\n",
    "df = pd.read_csv(full_file, index_col=False,names=['temp_hi', 'temp_lo', 'rainfall'])\n",
    "\n",
    "pd.set_option('display.max_rows', 1440)\n",
    "pd.set_option('display.max_columns', 35)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "max_temp  = (df.sort_values(by='temp_hi', ascending=False))\n",
    "max_T = max_temp.iloc[:1]\n",
    "maxT = max_T['temp_hi'].values[0]\n",
    "maxT = round(maxT)\n",
    "\n",
    "min_temp  = (df.sort_values(by='temp_lo', ascending=True))\n",
    "min_T = min_temp.iloc[:1]\n",
    "minT = min_T['temp_lo'].values[0]\n",
    "minT = round(minT)\n",
    "minT = str(minT)\n",
    "minT = minT.strip()\n",
    "\n",
    "totR = df['rainfall'].sum()\n",
    "totR = round(totR,2)\n",
    "\n",
    "# write the data to a csv file with an html suffix\n",
    "\n",
    "\n",
    "with open(f'{html_dir}HiLoRain.csv', 'w') as outfile:\n",
    "    print(f'{maxT},{minT},{totR}',file = outfile)\n",
    " \n",
    "\n",
    "#Write to an HTML for display\n",
    "df1 = pd.read_csv(f'{html_dir}HiLoRain.csv', names = ['High','Low','Rainfall'], index_col = False)\n",
    "pd.set_option('display.precision', 2)\n",
    "df1_style = df1.style.set_properties(**{\"background-color\": \"lightblue\",  \n",
    "                           \"color\" : \"black\",\n",
    "                           \"border\" : \"1.5px black\",\n",
    "                           \"text-align\": \"center\",\n",
    "                           \"font-weight\": \"bold\",\n",
    "                           \"font-size\": \"20px\"})\n",
    "\n",
    "df1.to_html(f'{html_dir}SoFarTest.html', index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_html('{html_dir}SoFarTest.html')\n",
    "a = df2[0]\n",
    "df3 = pd.DataFrame(a)\n",
    "properties = {\"color\": \"black\", \"font-size\": \"20px\", \"background-color\":\"lightblue\", \"text-align\":\"center\"}\n",
    "df3_style = df3.style.set_properties(**properties)\n",
    "df3_style.hide(axis = 'index')\n",
    "df3_style.format({'Rainfall':\"{:.2f}\"})\n",
    "\n",
    "df3_style.to_html(f'{html_dir}v1.html', index=False, justify ='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip out offending lines in the hmtl file created in the previous section\n",
    "\n",
    "values = ['>&nbsp;</th>\\n','level0 row0\" >0</th>\\n']\n",
    "\n",
    "with open(f'{html_dir}v1.html', 'r') as ff:\n",
    "         lines = ff.readlines()\n",
    "         \n",
    "with open(f'{html_dir}obsFinal.html', 'w') as fg:\n",
    "         for line in lines:\n",
    "                \n",
    "                result = any(map(line.endswith, values))\n",
    "                if result == False:\n",
    "                    fg.writelines(line)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "import requests\n",
    "import csv\n",
    "import re\n",
    "import calcOneDay\n",
    "\n",
    "# Calculate the time and date for end of day calculations\n",
    "\n",
    "xy = calcOneDay.calcOneDay()\n",
    "start, end = (xy[0], xy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name: \"api-key\" has value \"vy8jbrjsxlbwgojepq3vfyfqfywyhvbd\"\n",
      "Parameter name: \"api-secret\" has value \"sdqfm6wdfy9w0pqp2vdka38o6b4vcsvc\"\n",
      "Parameter name: \"end-timestamp\" has value \"1678338968\"\n",
      "Parameter name: \"start-timestamp\" has value \"1678252568\"\n",
      "Parameter name: \"station-id\" has value \"81211\"\n",
      "Parameter name: \"t\" has value \"1678338969\"\n",
      "Data string to hash is: \"api-keyvy8jbrjsxlbwgojepq3vfyfqfywyhvbdend-timestamp1678338968start-timestamp1678252568station-id81211t1678338969\"\n",
      "\n",
      "\n",
      "API Signature is: \"f01f81e952de0fb1dc9f44e9f2439bb7bba377f4c0ac3c8d04f03b0efc45d058\"\n",
      "\n",
      "\n",
      "https://api.weatherlink.com/v2/historic/81211?api-key=vy8jbrjsxlbwgojepq3vfyfqfywyhvbd&t=1678338969&start-timestamp=1678252568&end-timestamp=1678338968&api-signature=f01f81e952de0fb1dc9f44e9f2439bb7bba377f4c0ac3c8d04f03b0efc45d058\n",
      "<Response [200]>\n",
      "/home/ec2-user/Davis_20230309.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/83tjf6dx2d591wslk5wm2wdh0000gn/T/ipykernel_57628/1494688249.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFile_ec2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m      \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import hashlib\n",
    "import hmac\n",
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import dataFile\n",
    "\n",
    "parameters = {\n",
    "  \"api-key\": \"vy8jbrjsxlbwgojepq3vfyfqfywyhvbd\", \n",
    "  \"api-secret\": \"sdqfm6wdfy9w0pqp2vdka38o6b4vcsvc\",\n",
    "  \"station-id\": 81211, \n",
    "  \"end-timestamp\": end,\n",
    "  \"start-timestamp\": start,\n",
    "  \"t\": int(time.time())\n",
    "}\n",
    "\n",
    "parameters = collections.OrderedDict(sorted(parameters.items()))\n",
    "\n",
    "for key in parameters:\n",
    "    print(\"Parameter name: \\\"{}\\\" has value \\\"{}\\\"\".format(key, parameters[key]))\n",
    "\n",
    "apiSecret = parameters[\"api-secret\"];\n",
    "parameters.pop(\"api-secret\", None);\n",
    "\n",
    "data = \"\"\n",
    "for key in parameters:\n",
    "    data = data + key + str(parameters[key])\n",
    "\n",
    "print(\"Data string to hash is: \\\"{}\\\"\".format(data))\n",
    "print('\\n')\n",
    "\n",
    "\"\"\"\n",
    "Calculate the HMAC SHA-256 hash that will be used as the API Signature.\n",
    "\"\"\"\n",
    "apiSignature = hmac.new(\n",
    "  apiSecret.encode('utf-8'),\n",
    "  data.encode('utf-8'),\n",
    "  hashlib.sha256\n",
    ").hexdigest()\n",
    "\n",
    "\"\"\"\n",
    "Let's see what the final API Signature looks like.\n",
    "\"\"\"\n",
    "print(\"API Signature is: \\\"{}\\\"\".format(apiSignature))\n",
    "print('\\n')\n",
    "\n",
    "# Building the URL to get the station\n",
    "\n",
    "first_part = ('https://api.weatherlink.com/v2/historic/81211?')\n",
    "api_key = ('api-key=vy8jbrjsxlbwgojepq3vfyfqfywyhvbd')\n",
    "add_apisig = ('&api-signature=')\n",
    "add_t = ('&t='+ str(int(time.time())))\n",
    "\n",
    "start1 = \"&start-timestamp=\" + start\n",
    "end1 = \"&end-timestamp=\" + end\n",
    "\n",
    "#\n",
    "URLfinal = (first_part + api_key + add_t + start1 + end1 + add_apisig + apiSignature)\n",
    "print(URLfinal)\n",
    "\n",
    "r =  requests.get(URLfinal)\n",
    "print(r)\n",
    "data_file = dataFile.dataFile_ec2()\n",
    "print(data_file)\n",
    "with open(data_file, \"w\") as fd:   \n",
    "     json.dump(r.json(), fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/83tjf6dx2d591wslk5wm2wdh0000gn/T/ipykernel_57628/4107158043.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataFile_ec2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdavisAPI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "import dataFile\n",
    "\n",
    "data_file = dataFile.dataFile_ec2()\n",
    "\n",
    "with open(data_file) as fr:\n",
    "    davisAPI = json.load(fr) \n",
    "    \n",
    "a = davisAPI['sensors']    \n",
    "b = a[1]\n",
    "c = (b['data'])\n",
    "cLen = len(c)\n",
    "print(cLen)\n",
    "print(data_file)\n",
    "\n",
    "with open(data_file, 'w') as outfile: \n",
    "    i = 0\n",
    "    while i < cLen:\n",
    "        d = c[i]\n",
    "        hi_temp = (d['temp_hi'])\n",
    "        lo_temp = (d['temp_lo'])\n",
    "        rainfall = (d['rainfall_in'])\n",
    "        print(f'{hi_temp},{lo_temp},{rainfall}', file = outfile)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/Davis_20230309.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/m3/83tjf6dx2d591wslk5wm2wdh0000gn/T/ipykernel_57628/3529720287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temp_hi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'temp_lo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rainfall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1440\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ec2-user/Davis_20230309.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dataFile\n",
    "import getPath\n",
    "\n",
    "path_name = getPath.getPath_ec2()\n",
    "full_file = dataFile.dataFile_ec2()\n",
    "\n",
    "df = pd.read_csv(full_file, index_col=False,names=['temp_hi', 'temp_lo', 'rainfall'])\n",
    "\n",
    "pd.set_option('display.max_rows', 1440)\n",
    "pd.set_option('display.max_columns', 35)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "max_temp  = (df.sort_values(by='temp_hi', ascending=False))\n",
    "max_T = max_temp.iloc[:1]\n",
    "maxT = max_T['temp_hi'].values[0]\n",
    "maxT = round(maxT)\n",
    "\n",
    "min_temp  = (df.sort_values(by='temp_lo', ascending=True))\n",
    "min_T = min_temp.iloc[:1]\n",
    "minT = min_T['temp_lo'].values[0]\n",
    "minT = round(minT)\n",
    "\n",
    "totR = df['rainfall'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Write to the appropriate Excel file\n",
    "#\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import excelFilename\n",
    "import calcTimeNow\n",
    "\n",
    "#\n",
    "# Create the month name for the xlsx filename\n",
    "#\n",
    "\n",
    "ds = calcTimeNow.calcTimeNow()\n",
    "now, myMonth, myYear, date = (ds[0],ds[1],ds[2],ds[3])\n",
    "vf = excelFilename.davis()\n",
    "xls_filename, path_name = (vf[0], vf[1])\n",
    "xls_fullfile = f'{path_name}{xls_filename}'\n",
    "\n",
    "wb = openpyxl.load_workbook(xls_fullfile)\n",
    "sheet = wb.active\n",
    "\n",
    "# Write headers first...\n",
    "a1 = sheet['A1']\n",
    "a1.value = \"Year\"\n",
    "b1 = sheet['B1']\n",
    "b1.value = myYear\n",
    "c1 = sheet['C1']\n",
    "c1.value = 'Month'\n",
    "d1 = sheet['D1']\n",
    "d1.value = myMonth\n",
    "\n",
    "a3 = sheet['A3']\n",
    "a3.value = \"Date\"\n",
    "b3 = sheet['B3']\n",
    "b3.value = 'High'\n",
    "c3 = sheet['C3']\n",
    "c3.value = 'Low'\n",
    "d3 = sheet['D3']\n",
    "d3.value = 'Average'\n",
    "\n",
    "e3 = sheet['E3']\n",
    "e3.value = \"HDD\"\n",
    "f3 = sheet['F3']\n",
    "f3.value = 'CDD'\n",
    "g3 = sheet['G3']\n",
    "g3.value = 'Rainfall'\n",
    "\n",
    "k4 = sheet['K4']\n",
    "k4.value = \"Highs >=90\"\n",
    "k5 = sheet['K5']\n",
    "k5.value = \"Highs <= 32\"\n",
    "k6 = sheet['K6']\n",
    "k6.value = 'Lows <= 32'\n",
    "k7 = sheet['K7']\n",
    "k7.value = 'Lows <= 0'\n",
    "\n",
    "k13 = sheet['K14']\n",
    "k13.value = \"Total Rainfall\"\n",
    "k14 = sheet['K15']\n",
    "k14.value = \"rain>=0.01\"\n",
    "k15 = sheet['K16']\n",
    "k15.value = 'rain>=0.10'\n",
    "k16 = sheet['K17']\n",
    "k16.value = 'rain>=0.50'\n",
    "k17= sheet['K18']\n",
    "k17.value = 'rain>=1.00'\n",
    "k23 = sheet['K24']\n",
    "k23.value = 'Monthly Average'\n",
    "k24 = sheet['K25']\n",
    "k24.value = 'Departure'\n",
    "\n",
    "m3 = sheet['M4']\n",
    "m3.value = \"High\"\n",
    "m4 = sheet['M5']\n",
    "m4.value = \"Low\"\n",
    "m13 = sheet['M14']\n",
    "m13.value = \"Max Rain\"\n",
    "m23 = sheet['M24']\n",
    "m23.value = \"Monthy Rainfall\"\n",
    "m24 = sheet['M25']\n",
    "m24.value = \"Departure\"\n",
    "\n",
    "o3 = sheet['O4']\n",
    "o3.value = \"Date\"\n",
    "o4 = sheet['O5']\n",
    "o4.value = \"Date\"\n",
    "\n",
    "\n",
    "# Calculate the date and write the data...\n",
    "offset_day = (int(date) + 2)\n",
    "\n",
    "maxTT = sheet.cell(row = offset_day, column = 2)\n",
    "maxTT.value = maxT\n",
    "minTT = sheet.cell(row = offset_day, column = 3)\n",
    "minTT.value = minT\n",
    "totRR = sheet.cell(row = offset_day, column = 7)\n",
    "totRR.value = totR\n",
    "\n",
    "wb.save(xls_fullfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setUpHTML\n",
    "\n",
    "# Read the Excel file as a possible pandas dataframe and html file\n",
    "\n",
    "xd  = setUpHTML.setUpHTML_davis()\n",
    "new_file,html_path = (xd[0],xd[1])\n",
    "\n",
    "df1 = pd.read_excel(new_file, skiprows = 2, names = ['Date','High','Low','Average','HDD','CDD','Rainfall','dead0','dead1','dead2','dead3','dead4','dead5','dead6','dead7'])\n",
    "df1 = df1.drop(df1.columns[[7,8,9,10,11,12,13,14]], axis = 1)\n",
    "df1\n",
    "df1.to_html(f'{html_path}testDavis.html', index = False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
